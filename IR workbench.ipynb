{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR-1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreedeepack/Q-Exchange/blob/main/IR%20workbench.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99swSMxfQ7WS"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abaJw4nUS-Ql",
        "outputId": "cfc4a9af-63ba-403a-a231-f4c56ee1bd5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "%pip install jsonlines"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonlines) (1.15.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOu3di9eRJJm"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from math import log10\n",
        "import jsonlines"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S42Jq1pVT0q7"
      },
      "source": [
        "## For Solr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOGF3F0_RvtP"
      },
      "source": [
        "import jsonlines\n",
        "from datetime import datetime\n",
        "\n",
        "def solr_clean(file):\n",
        "    \"\"\"\n",
        "    Return a generator for cleaned jsons from a file.\n",
        "    To be used with solr\n",
        "    \"\"\"\n",
        "    with jsonlines.open(file) as reader:\n",
        "        for obj in reader:\n",
        "            item = {}\n",
        "            item['url'] = obj['url']\n",
        "            item['src'] = obj['src']\n",
        "            item['title'] = clean_str(obj['title'])\n",
        "            try:\n",
        "                item['desc'] = clean_str(obj['desc'])\n",
        "                item['tags'] = obj['tags']\n",
        "                item['answers'] = obj['answers']\n",
        "\n",
        "            except KeyError:\n",
        "                item['desc'] = \"\"\n",
        "                item['tags'] = [\"reddit\"]\n",
        "                item['answers'] = obj['comments']\n",
        "\n",
        "\n",
        "            item['votes'] = obj['votes']\n",
        "\n",
        "            item['date'] = obj['date']\n",
        "            if item['date'] == 'NA':\n",
        "                item['date'] = datetime.today().isoformat()\n",
        "\n",
        "            yield item            \n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn-JS2MPT7ig"
      },
      "source": [
        "import json\n",
        "\n",
        "a_file = open(\"solr.jsonl\", \"a\")\n",
        "\n",
        "for json_obj in solr_clean(\"data/stack.jl\"):\n",
        "    json.dump(json_obj, a_file)\n",
        "    a_file.write(\"\\n\")\n",
        "\n",
        "for json_obj in solr_clean(\"data/reddit.jl\"):\n",
        "    json.dump(json_obj, a_file)\n",
        "    a_file.write(\"\\n\")\n",
        "\n",
        "a_file.close()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2P1G_tzMMGl"
      },
      "source": [
        "# Indexing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoFqfct7kggo"
      },
      "source": [
        "from functools import reduce\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from math import log10\n",
        "import jsonlines\n",
        "\n",
        "\n",
        "class Preprocessor(object):\n",
        "    \"\"\"\n",
        "    Cleans, removes stopwords and tokenizes lines\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Stopwords\n",
        "        nltk.download('stopwords', quiet=True, raise_on_error=True)\n",
        "        # Sentence Tokenizer\n",
        "        nltk.download('punkt', quiet=True, raise_on_error=True)\n",
        "\n",
        "        self._tokenized_stop_words = nltk.word_tokenize(' '.join(nltk.corpus.stopwords.words('english')))\n",
        "        self._stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "        # Porter stemmer\n",
        "        self.stemmer = nltk.stem.PorterStemmer()\n",
        "\n",
        "    def stem_word(self, word):\n",
        "        return self.stemmer.stem(word)  \n",
        "\n",
        "    def tokenize_string(self, line):\n",
        "        tokens = nltk.word_tokenize(line)\n",
        "        tokens = (self.stem_word(token) for token in tokens)\n",
        "        tokens = [token for token in tokens if token.isalnum()]\n",
        "        return list(tokens)      \n",
        "\n",
        "    def word_split(self, text):\n",
        "        \"\"\"\n",
        "        Split a text in words. Returns a list of tuple that contains\n",
        "        (word, location) location is the starting byte position of the word.\n",
        "        \"\"\"\n",
        "        word_list = []\n",
        "        w_current = []\n",
        "        w_index = None\n",
        "\n",
        "        for i, c in enumerate(text):\n",
        "            if c.isalnum():\n",
        "                w_current.append(c)\n",
        "                w_index = i\n",
        "            elif w_current:\n",
        "                word = u''.join(w_current)\n",
        "                word_list.append((w_index - len(word) + 1, word))\n",
        "                w_current = []\n",
        "\n",
        "        if w_current:\n",
        "            word = u''.join(w_current)\n",
        "            word_list.append((w_index - len(word) + 1, word))\n",
        "\n",
        "        return word_list\n",
        "\n",
        "    def words_cleanup(self, words):\n",
        "        \"\"\"\n",
        "        Stems words and removes\n",
        "        words with length less then a minimum and stopwords.\n",
        "        \"\"\"\n",
        "        cleaned_words = []\n",
        "        for index, word in words:\n",
        "        \n",
        "            if len(word) < 3 or word in self._stop_words or word in self._tokenized_stop_words:\n",
        "                continue\n",
        "            word = self.stem_word(word)\n",
        "            cleaned_words.append((index, word))\n",
        "        return cleaned_words\n",
        "   \n",
        "    def word_index(self, text):\n",
        "        \"\"\"\n",
        "        Just a helper method to process a text.\n",
        "        It calls word split, normalize and cleanup.\n",
        "        \"\"\"\n",
        "        words = self.word_split(text)\n",
        "        words = self.words_cleanup(words)\n",
        "\n",
        "        return words\n",
        "\n",
        "class Indexer(object):\n",
        "\n",
        "    def __init__(self, preprocessor):\n",
        "        self.preprocessor = preprocessor\n",
        "\n",
        "    def inverted_index(self, text):\n",
        "        \"\"\"\n",
        "        Create an Inverted-Index of the specified text document.\n",
        "            {word:[locations]}\n",
        "        \"\"\"\n",
        "        inverted = {}\n",
        "\n",
        "        for index, word in self.preprocessor.word_index(text):\n",
        "            locations = inverted.setdefault(word, [])\n",
        "            locations.append(index)\n",
        "\n",
        "        return inverted\n",
        "\n",
        "    @staticmethod\n",
        "    def inverted_index_add(inverted, doc_id, doc_index):\n",
        "        \"\"\"\n",
        "        Add Inverted-Index doc_index of the document doc_id to the\n",
        "        Multi-Document Inverted-Index (inverted),\n",
        "        using doc_id as document identifier.\n",
        "            {word:{doc_id:[locations]}}\n",
        "        \"\"\"\n",
        "        for word, locations in doc_index.items():\n",
        "            indices = inverted.setdefault(word, {})\n",
        "            indices[doc_id] = locations\n",
        "        return inverted\n",
        "\n",
        "    def search(self, inverted, query):\n",
        "        \"\"\"\n",
        "        Returns a set of documents id that contains all the words in your query.\n",
        "        \"\"\"\n",
        "        words = [word for _, word in self.preprocessor.word_index(query) if word in inverted]\n",
        "        results = [set(inverted[word].keys()) for word in words]\n",
        "        return reduce(lambda x, y: x & y, results) if results else []\n"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF4qTwtQlVdw"
      },
      "source": [
        "import jsonlines\n",
        "\n",
        "def clean_str(text) :\n",
        "        text = (text.encode('ascii', 'ignore')).decode(\"utf-8\")\n",
        "        text = re.sub(\"&.*?;\", \"\", text)\n",
        "        text = re.sub(\"[\\]\\|\\[\\@\\,\\$\\%\\*\\&\\\\\\(\\)\\\":]\", \"\", text)\n",
        "        text = re.sub(\"-\", \" \", text)\n",
        "        text = re.sub(\"\\.+\", \"\", text)\n",
        "        text = re.sub(\"^\\s+\",\"\" ,text)\n",
        "        text = re.sub(\"\\.+\", \"\", text)\n",
        "        text = text.lower()\n",
        "        return text\n",
        "\n",
        "def document_generator(file):\n",
        "    tokenizer = Tokenizer()\n",
        "    with jsonlines.open(file) as reader:\n",
        "        for id, obj in enumerate(reader):\n",
        "            item = {}\n",
        "            item['doc_id'] = id\n",
        "            item['url'] = obj['url']\n",
        "            item['title'] = clean_str(obj['title'])\n",
        "            item['desc'] = clean_str(obj['desc'])\n",
        "\n",
        "            yield item\n"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1Uepp5HlDyB"
      },
      "source": [
        "inverted = defaultdict()\n",
        "doc_map = {}\n",
        "\n",
        "p = Preprocessor()\n",
        "indexer = Indexer(p)\n",
        "\n",
        "for doc in document_generator(\"solr.jsonl\"):\n",
        "\n",
        "    doc_id = doc['doc_id']   \n",
        "    text = doc['title'] + \" \" +doc['desc']\n",
        "\n",
        "    # doc_map[doc_id] = (doc['url'], doc['title'])\n",
        "    doc_map[doc_id] = (doc['url'], text)\n",
        "\n",
        "    doc_index = indexer.inverted_index(text)\n",
        "    indexer.inverted_index_add(inverted, doc_id, doc_index)\n",
        "\n",
        "# Print Inverted-Index\n",
        "i = 0\n",
        "for word, doc_locations in inverted.items():\n",
        "    print(word, doc_locations)\n",
        "    i += 1\n",
        "    if i>15:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDcZUzwJs2PD",
        "outputId": "69aa2bae-a161-47c3-c742-b895d6734417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Search something and print results\n",
        "queries = ['dolby', 'vim emacs', 'github week']\n",
        "\n",
        "for query in queries:\n",
        "    \n",
        "    tokenized_query = ' '.join(p.tokenize_string(query))\n",
        "    result_docs = indexer.search(inverted, tokenized_query)\n",
        "    print(f\"Search for '{query}': doc_ids={result_docs}\")\n",
        "    \n",
        "    for _, word in word_index(tokenized_query):\n",
        "        def extract_text(doc, position): \n",
        "            return doc_map[doc][1][position:position+30].replace(\"\\n\", ' ')\n",
        "\n",
        "        for doc_id in result_docs:\n",
        "            for position in inverted[word][doc_id]:\n",
        "                print(\n",
        "                    f\"\\t - {extract_text(doc_id, position)}...\"\n",
        "                    f\"\\n\\t -->{doc_map[doc_id][0]}\"\n",
        "                )"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search for 'dolby': doc_ids={11074}\n",
            "\t - dolby digital expires at midni...\n",
            "\t -->/r/programming/comments/60b7kv/the_last_patent_on_ac3_dolby_digital_expires_at/\n",
            "Search for 'vim emacs': doc_ids={3942, 2058, 2672, 3315, 3732, 4221, 1431, 2587, 2877}\n",
            "\t - vim running inside gnome termi...\n",
            "\t -->https://askubuntu.com/questions/48299/what-ides-are-available-for-ubuntu\n",
            "\t - vim splits or extra tabs you l...\n",
            "\t -->https://askubuntu.com/questions/48299/what-ides-are-available-for-ubuntu\n",
            "\t - vim emacs nano gedit kate to n...\n",
            "\t -->https://askubuntu.com/questions/68918/how-do-i-restrict-my-kids-computing-time\n",
            "\t - vim or emacs to write c code  ...\n",
            "\t -->https://askubuntu.com/questions/61408/what-is-a-command-to-compile-and-run-c-programs\n",
            "\t - vim is amazing! vim is a highl...\n",
            "\t -->https://askubuntu.com/questions/10998/what-developer-text-editors-are-available-for-ubuntu\n",
            "\t - vim is a highly configurable t...\n",
            "\t -->https://askubuntu.com/questions/10998/what-developer-text-editors-are-available-for-ubuntu\n",
            "\t - vim was originally released fo...\n",
            "\t -->https://askubuntu.com/questions/10998/what-developer-text-editors-are-available-for-ubuntu\n",
            "\t - vim has since been developed t...\n",
            "\t -->https://askubuntu.com/questions/10998/what-developer-text-editors-are-available-for-ubuntu\n",
            "\t - vim is free and open source so...\n",
            "\t -->https://askubuntu.com/questions/10998/what-developer-text-editors-are-available-for-ubuntu\n",
            "\t - vim text editor dpkg apt less ...\n",
            "\t -->https://askubuntu.com/questions/162075/my-computer-boots-to-a-black-screen-what-options-do-i-have-to-fix-it\n",
            "\t - vim style keys and searching l...\n",
            "\t -->https://askubuntu.com/questions/162075/my-computer-boots-to-a-black-screen-what-options-do-i-have-to-fix-it\n",
            "\t - vim or pico/nano or check your...\n",
            "\t -->https://askubuntu.com/questions/162075/my-computer-boots-to-a-black-screen-what-options-do-i-have-to-fix-it\n",
            "\t - vim users like i that prefers ...\n",
            "\t -->https://stackoverflow.com/questions/161813/how-to-resolve-merge-conflicts-in-git\n",
            "\t - vim called   once installed yo...\n",
            "\t -->https://stackoverflow.com/questions/161813/how-to-resolve-merge-conflicts-in-git\n",
            "\t - vim ~/profile in file put my_e...\n",
            "\t -->https://stackoverflow.com/questions/135688/setting-environment-variables-on-os-x\n",
            "\t - vim it gives you all the tools...\n",
            "\t -->https://askubuntu.com/questions/10607/how-can-i-rename-many-files-at-once\n",
            "\t - vim or emacs in a python ide o...\n",
            "\t -->https://askubuntu.com/questions/6588/is-there-a-visual-studio-style-tool-ide\n",
            "\t - emacs but for command line pro...\n",
            "\t -->https://askubuntu.com/questions/48299/what-ides-are-available-for-ubuntu\n",
            "\t - emacs nano gedit kate to name ...\n",
            "\t -->https://askubuntu.com/questions/68918/how-do-i-restrict-my-kids-computing-time\n",
            "\t - emacs to write c code  just tr...\n",
            "\t -->https://askubuntu.com/questions/61408/what-is-a-command-to-compile-and-run-c-programs\n",
            "\t - emacs it has a solid python mo...\n",
            "\t -->https://askubuntu.com/questions/10998/what-developer-text-editors-are-available-for-ubuntu\n",
            "\t - emacs tutorial it should be ea...\n",
            "\t -->https://askubuntu.com/questions/10998/what-developer-text-editors-are-available-for-ubuntu\n",
            "\t - emacs vim or pico/nano or chec...\n",
            "\t -->https://askubuntu.com/questions/162075/my-computer-boots-to-a-black-screen-what-options-do-i-have-to-fix-it\n",
            "\t - emacs type this will open thre...\n",
            "\t -->https://stackoverflow.com/questions/161813/how-to-resolve-merge-conflicts-in-git\n",
            "\t - emacs asks you if you want to ...\n",
            "\t -->https://stackoverflow.com/questions/161813/how-to-resolve-merge-conflicts-in-git\n",
            "\t - emacs lisp function although o...\n",
            "\t -->https://stackoverflow.com/questions/135688/setting-environment-variables-on-os-x\n",
            "\t - emacs lisp function  note this...\n",
            "\t -->https://stackoverflow.com/questions/135688/setting-environment-variables-on-os-x\n",
            "\t - emacs i think nothing beats di...\n",
            "\t -->https://askubuntu.com/questions/10607/how-can-i-rename-many-files-at-once\n",
            "\t - emacs that often you may find ...\n",
            "\t -->https://askubuntu.com/questions/10607/how-can-i-rename-many-files-at-once\n",
            "\t - emacs dired mode for a directo...\n",
            "\t -->https://askubuntu.com/questions/10607/how-can-i-rename-many-files-at-once\n",
            "\t - emacs uses a different syntax ...\n",
            "\t -->https://askubuntu.com/questions/10607/how-can-i-rename-many-files-at-once\n",
            "\t - emacs in a python ide or wingi...\n",
            "\t -->https://askubuntu.com/questions/6588/is-there-a-visual-studio-style-tool-ide\n",
            "Search for 'github week': doc_ids={4710, 9863, 2058, 5835, 3850, 10127, 2511, 4498, 4221, 3286, 2268, 3741}\n",
            "\t - github repo  another option yo...\n",
            "\t -->https://stackoverflow.com/questions/292926/robust-and-mature-html-parser-for-php\n",
            "\t - github protest over chinese te...\n",
            "\t -->/r/programming/comments/b799yb/github_protest_over_chinese_tech_companies_996/\n",
            "\t - github at the following locati...\n",
            "\t -->https://askubuntu.com/questions/68918/how-do-i-restrict-my-kids-computing-time\n",
            "\t - github repo i didn't know what...\n",
            "\t -->https://stackoverflow.com/questions/38922754/how-to-use-threetenabp-in-android-project\n",
            "\t - github has an api and today i ...\n",
            "\t -->https://askubuntu.com/questions/1056077/how-to-install-latest-hplip-on-my-ubuntu-to-support-my-hp-printer-and-or-scanner\n",
            "\t - github ...\n",
            "\t -->/r/programming/comments/henwet/the_uk_gov_just_spent_118_million_on_a_covid/\n",
            "\t - github repo that houses the so...\n",
            "\t -->https://askubuntu.com/questions/548003/how-do-i-install-the-firefox-developer-edition\n",
            "\t - github i found the    this lib...\n",
            "\t -->https://stackoverflow.com/questions/2900023/change-app-language-programmatically-in-android\n",
            "\t - github page the localizationac...\n",
            "\t -->https://stackoverflow.com/questions/2900023/change-app-language-programmatically-in-android\n",
            "\t - github for practical tutorial ...\n",
            "\t -->https://stackoverflow.com/questions/161813/how-to-resolve-merge-conflicts-in-git\n",
            "\t - github's native tool  explains...\n",
            "\t -->https://stackoverflow.com/questions/161813/how-to-resolve-merge-conflicts-in-git\n",
            "\t - github   repository named   th...\n",
            "\t -->https://askubuntu.com/questions/922085/i-need-rules-to-drop-some-malicious-apache-connections\n",
            "\t - github here are over viewed fe...\n",
            "\t -->https://askubuntu.com/questions/922085/i-need-rules-to-drop-some-malicious-apache-connections\n",
            "\t - github which satisfies the lik...\n",
            "\t -->https://askubuntu.com/questions/432542/is-ffmpeg-missing-from-the-official-repositories-in-14-04\n",
            "\t - github and extract it in a dir...\n",
            "\t -->https://askubuntu.com/questions/775579/recovering-broken-or-deleted-ntfs-partitions\n",
            "\t - week the pyquery parsing broke...\n",
            "\t -->https://stackoverflow.com/questions/292926/robust-and-mature-html-parser-for-php\n",
            "\t - week ago i created a library n...\n",
            "\t -->https://stackoverflow.com/questions/292926/robust-and-mature-html-parser-for-php\n",
            "\t - week chinese tech companies re...\n",
            "\t -->/r/programming/comments/b799yb/github_protest_over_chinese_tech_companies_996/\n",
            "\t - week using the following abbre...\n",
            "\t -->https://askubuntu.com/questions/68918/how-do-i-restrict-my-kids-computing-time\n",
            "\t - week finally change the field ...\n",
            "\t -->https://askubuntu.com/questions/68918/how-do-i-restrict-my-kids-computing-time\n",
            "\t - weeks ago when i started learn...\n",
            "\t -->https://stackoverflow.com/questions/38922754/how-to-use-threetenabp-in-android-project\n",
            "\t - weeks ago the latest hplip dri...\n",
            "\t -->https://askubuntu.com/questions/1056077/how-to-install-latest-hplip-on-my-ubuntu-to-support-my-hp-printer-and-or-scanner\n",
            "\t - week project thats failed to d...\n",
            "\t -->/r/programming/comments/henwet/the_uk_gov_just_spent_118_million_on_a_covid/\n",
            "\t - weeks before they reach the ma...\n",
            "\t -->https://askubuntu.com/questions/548003/how-do-i-install-the-firefox-developer-edition\n",
            "\t - weeks after they have stabiliz...\n",
            "\t -->https://askubuntu.com/questions/548003/how-do-i-install-the-firefox-developer-edition\n",
            "\t - weeks the new way to do this i...\n",
            "\t -->https://stackoverflow.com/questions/2900023/change-app-language-programmatically-in-android\n",
            "\t - week period you may choose to ...\n",
            "\t -->https://stackoverflow.com/questions/161813/how-to-resolve-merge-conflicts-in-git\n",
            "\t - week that way if you do find m...\n",
            "\t -->https://stackoverflow.com/questions/161813/how-to-resolve-merge-conflicts-in-git\n",
            "\t - weeks to merge everything toge...\n",
            "\t -->https://stackoverflow.com/questions/161813/how-to-resolve-merge-conflicts-in-git\n",
            "\t - week     according to   i crea...\n",
            "\t -->https://askubuntu.com/questions/922085/i-need-rules-to-drop-some-malicious-apache-connections\n",
            "\t - weeks we will announce   here ...\n",
            "\t -->https://askubuntu.com/questions/432542/is-ffmpeg-missing-from-the-official-repositories-in-14-04\n",
            "\t - weeks to install newest versio...\n",
            "\t -->https://askubuntu.com/questions/432542/is-ffmpeg-missing-from-the-official-repositories-in-14-04\n",
            "\t - weeks ago i had a problem with...\n",
            "\t -->https://askubuntu.com/questions/775579/recovering-broken-or-deleted-ntfs-partitions\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}